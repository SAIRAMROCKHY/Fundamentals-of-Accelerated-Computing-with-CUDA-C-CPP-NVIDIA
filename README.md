# CUDA C/C++ Acceleration Workshop

Welcome to the CUDA C/C++ Acceleration Workshop repository! This workshop focuses on teaching fundamental tools and techniques to accelerate C/C++ applications using CUDA on massively parallel GPUs.

## About this Course

This workshop teaches participants how to write and optimize CUDA C/C++ code for GPU execution. You'll learn to parallelize code, manage memory efficiently between CPU and GPU, and accelerate CPU-only applications using CUDA. By the end of the workshop, you'll gain practical skills and access to resources to develop GPU-accelerated applications independently.

### Learning Objectives

By the end of this workshop, participants will:
- Write GPU-accelerated C/C++ code.
- Implement data and instruction-level parallelism using CUDA.
- Optimize memory migration using CUDA-managed memory and asynchronous prefetching.
- Utilize command-line and visual profilers for performance optimization.
- Implement concurrent CUDA streams for increased parallelism.
- Refactor CPU-only applications into GPU-accelerated applications using profile-driven optimization.

## Topics Covered

### Duration: 8 hours

### Technologies:
- NVIDIA® Nsight™
- nsys

### Certificate:
Upon successful completion, participants will receive an NVIDIA DLI certificate.

### Hardware Requirements:
Desktop or laptop computer capable of running the latest Chrome or Firefox. Each participant will access a fully configured GPU-accelerated server in the cloud.

### Languages:
English, Japanese, Korean, Simplified Chinese, Traditional Chinese

## Course Outline

### Introduction
- Meet the instructor.
- Create an account at courses.nvidia.com/join.

### Accelerating Applications with CUDA C/C++
- Learn essential syntax and concepts for GPU-enabled C/C++ applications with CUDA:
  - Write, compile, and run GPU code.
  - Control parallel thread hierarchy.
  - Allocate and free GPU memory.

### Break
- Duration: 60 mins

### Managing Accelerated Application Memory with CUDA C/C++
- Use command-line profilers and CUDA-managed memory:
  - Profile CUDA code.
  - Understand unified memory.
  - Optimize memory management.

### Break
- Duration: 15 mins

### Asynchronous Streaming and Visual Profiling
- Improve memory management and parallelism:
  - Profile CUDA code with NVIDIA Nsight Systems.
  - Utilize concurrent CUDA streams.

### Final Review
- Review key learnings and answer questions.
- Complete the assessment to earn a certificate.
- Fill out the workshop survey.

---
